<<echo=FALSE, cache=FALSE>>=
set_parent('r4p.main.Rnw')
opts_knit$set(concordance=TRUE)
@

\chapter{Algorithms}\label{chap:algorithms}

%\begin{abstract}
%  In this chapter we explain how UV and VIS radiation can drive chemical reactions, both in inorganic and organic molecules, both \emph{in vitro} and within living organisms. We also describe how action- and response spectra are measured.
%\end{abstract}

\section{Integration}\label{sec:algo:integration}

\begin{framed}
\ilAttention\textbf{What is wrong with adding-up spectral quantities to obtain a total?} With most spectrometers one can optionally export the spectral data re-expressed with wavelengths at 1 nm intervals. With any other step-size for wavelength, simplistically summing the spectral values will produce erroneous results. When re-expressed to 1~nm-step, the differences would frequently be only minor. However, interpolation and/or moving averages can distort narrow peaks and result in lost information. Although in many cases it leads to small differences between the values obtained by integration of the original data and the integration data re-expressed at different wavelengths, if the data were measured at a much finer wavelength resolution than the one it is re-expressed at, the loss of information can be important.

Functions in the photobiology package take the mean between each pair of spectral irradiance values at contiguous discrete wavelength values, and multiplies them by the distance in nm between these two wavelengths. This needs to be done individually for each of the pixels. It can be programmed in e.g.\ Excel, but summing up the values and multiplying by the mean interval will not give the correct integral for instruments with array detectors. The values obtained will be biased. This is because the intervals do not vary randomly, they increase in width as a function of the wavelength. This results in giving more weight to readings at one end of the spectrum than at the other. So, the error will depend on the shape of the emission spectrum of the light source.
\end{framed}

\subsection{Area under a spectral curve}

Summary quantities over a range of wavelengths, are geometrically represented by the area under the spectral curve for the region delimited by the two extreme wavelengths in the range of interest ($\lambda_1$ and $\lambda_n$ in Figure \ref{fig:integral}. Mathematically the operation is the computation of an integral over wavelengths.

\begin{figure}
\pgfplotsset{
    integral axis/.style={
        axis lines=middle,
        enlarge y limits=upper,
        axis equal image, width=12cm,
        xlabel=$\lambda$, ylabel=$E(\lambda)$,
        ytick=\empty,
        xticklabel style={font=\small, text height=1.5ex, anchor=north},
        samples=100
    },
    integral/.style={
            domain=2:10,
            samples=100
    },
    integral fill/.style={
            integral,
            draw=none, fill=#1,
            on layer=axis background
        },
        integral fill/.default=blue!10,
        integral line/.style={
            integral,
%            very thick,
            draw=#1
        },
        integral line/.default=black
}

\centering

\begin{tikzpicture}[
    % The function that is used for all the plots
    declare function={f=x/5-cos(deg(x*1.85))/2+2;}
]
\begin{axis}[
    integral axis,
    ymin=0,
    xmin=0.75, xmax=11.25,
    domain=1.5:10.5,
    xtick={2,...,10},
    xticklabels={$a=\lambda_1$, $\lambda_2$,,,$\lambda_{j-1}$,$\lambda_j$,,$\lambda_{n-1}$,$b=\lambda_n$},
]
% The filled area under the approximate integral
\addplot [integral fill=blue!10] {f} \closedcycle;

% The approximate integral
\addplot [integral line=black] {f};

% The vertical lines between the segments
%\addplot [integral, ycomb=blue] {f};

% The function
\addplot [thick, black] {f} node [anchor=south] {$E(\lambda)$};

% The highlighted segment
%\addplot [integral fill=cyan!35, domain=6:7, samples=2] {f} \closedcycle;
\end{axis}
\end{tikzpicture}
  \caption[The integral]{The actual integral without approximation.}\label{fig:integral}
\end{figure}

<<echo=FALSE,cache=FALSE,message=my.debug,eval=TRUE>>=
library(ggplot2)
library(photobiology)
library(photobiologyLEDs)
library(photobiologyWavebands)
library(ggspectra)
@

<<echo=FALSE, include=FALSE, cache=FALSE, eval=TRUE>>=
opts_chunk$set(opts_fig_wide)
@

<<echo = FALSE, eval=FALSE>>=
flat.spct <- source_spct(w.length = 250:900, s.e.irrad = 1)
autoplot(flat.spct, annotations = NULL) +
    geom_line() +
    stat_wl_summary(range = PAR(), geom = "rect", alpha = 0.15, color="blue", fill="blue") + annotate(geom = "text", x = 550, y = 0.5, color = "black", size = 6,
             label = "integral(E(lambda)~d*lambda, 400, 700)",
             parse = TRUE) +
    xlab(expression(Wavelength~~lambda~~(nm))) +
    theme_bw()
@

Only if the wavelength step, $\Delta \lambda = 1$~nm, and uniform across the whole spectrum,
\begin{equation} \label{eq:plain:sum}
  \int_{400}^{700} E(\lambda) \mathrm{d}\lambda \approxeq \sum_{i = 400}^{699} E_i
\end{equation}
if $\Delta \lambda \neq 1$~nm, but uniform, then this needs to be taken into account,
\begin{equation}\label{eq:delta:sum}
  \int_{400}^{700} E(\lambda) \mathrm{d}\lambda \approxeq \sum_{i=1}^{n-1} E_i \cdot \Delta \lambda .
\end{equation}
In equation \ref{eq:delta:sum} we multiply by the width of the wavelength step after summing the spectral irradiance values as this value is the same for all the observations included.

In equation \ref{eq:plain:sum} we sum 300 spectral irradiance values, if we would add both ends, then area would cover 301~nm instead of 300~nm.In both equations above we avoided this overestimation by excluding the observation at 700~nm. This approach can lead to bias. To avoid this bias we would need to take the average of the two extremes, in the case the wavelengths are measured (or interpolated) at the exact wavelengths without decimals. Only in the case when measurements are at wavelength values $\lambda_1 = 400.5; \lambda_2 = 401.5 \ldots \lambda_{300} = 699.5$~nm, adding up these numbers would give an approximation of the correct irradiance. Figure \ref{fig:delta:sum} shows this case graphically, but with only eight and broad wavelength steps drawn.

If $\Delta \lambda < 1$~nm, using equation \ref{eq:plain:sum} instead of equation \ref{eq:delta:sum} would be represented in Figure \ref{fig:delta:sum} by overlapping rectangles, leading to overestimation by a factor equal to $1 / \Delta \lambda$. In contrast, if $\Delta \lambda > 1$~nm, there would be gaps in between the columns, leading to underestimation.

\begin{figure}
    \pgfplotsset{
        axis equal image, width=12cm,
        integral segments/.code={\pgfmathsetmacro\integralsegments{#1}},
        integral segments=8,
        integral/.style args={#1:#2}{
            ybar interval,
            domain=#1+((#2-#1)/\integralsegments)/2:#2+((#2-#1)/\integralsegments)/2,
            samples=\integralsegments+1,
            x filter/.code=\pgfmathparse{\pgfmathresult-((#2-#1)/\integralsegments)/2}
        }
    }

  \centering
    \begin{tikzpicture}[declare function={f=x/5-cos(deg(x*1.85))/2+2;}]
    \begin{axis}[
        enlarge y limits=upper,
        xlabel=$\lambda$, ylabel=$E(\lambda)$,
        ymin=0,
        xmin=0.75, xmax=11.25,
        domain=1.5:10.5,
        samples=100,
        axis lines=middle,
        ytick=\empty,
        xtick={2,...,10},
        xticklabels={$a=\lambda_1$, $\lambda_2$,,,$\lambda_{j-1}$,$\lambda_j$,,$\lambda_{n-1}$,$b=\lambda_n$},
    ]
    \addplot [
        fill=blue!10,
        integral=2:10
    ] {f};
    \addplot [thick] {f} node [anchor=south] {$E(\lambda)$};
    \end{axis}
    \end{tikzpicture}
  \caption[Integration as a sum]{The sum of discrete observed values, is an approximation
   based on rectangles if their width is taken into account.}\label{fig:delta:sum}
\end{figure}


In array spectrometers the actual measurements are not done at a constant pixel resolution. Instead, due to optical constraints, the wavelength step changes smoothly from pixel to pixel. Adding up observations will in such cases result in erroneous estimates of irradiance. Probably, the simplest method of numerical integration is the rule of the parallelogram. This method is an approximation, but not biased, and can be used with non-uniform $\Delta \lambda$. It is reliable when the number of observations in the range of wavelengths to be integrated is large enough to ``track'' the shape of the spectrum. Figure \ref{fig:trapezium:rule} shows the trapezium rule applied to a spectrum.

\begin{equation}\label{eq:trapezium:integral}
  \int_{400}^{700} E(\lambda) \mathrm{d}\lambda \approxeq \sum_{i = 1}^{n-1} \frac{E_i + E_{i+1}}{2} \cdot (\lambda_{i+1} - \lambda_i)
\end{equation}

Equation \ref{eq:trapezium:integral} is directly applicable only if the data contains observations exactly at the boundaries of the range of wavelengths to be integrated. Otherwise the ends must be handled as special cases, calculating $\Delta \lambda$ using the extremes of the integration range instead of the wavelength corresponding to the observations immediately outside of the range.

\begin{figure}
\pgfplotsset{
    integral axis/.style={
        axis lines=middle,
        enlarge y limits=upper,
        axis equal image, width=12cm,
        xlabel=$\lambda$, ylabel=$E(\lambda)$,
        ytick=\empty,
        xticklabel style={font=\small, text height=1.5ex, anchor=north},
        samples=100
    },
    integral/.style={
            domain=2:10,
            samples=9
    },
    integral fill/.style={
            integral,
            draw=none, fill=#1,
            on layer=axis background
        },
        integral fill/.default=blue!10,
        integral line/.style={
            integral,
%            very thick,
            draw=#1
        },
        integral line/.default=black
}

\centering

\begin{tikzpicture}[
    % The function that is used for all the plots
    declare function={f=x/5-cos(deg(x*1.85))/2+2;}
]
\begin{axis}[
    integral axis,
    ymin=0,
    xmin=0.75, xmax=11.25,
    domain=1.5:10.5,
    xtick={2,...,10},
    xticklabels={$a=\lambda_1$, $\lambda_2$,,,$\lambda_{j-1}$,$\lambda_j$,,$\lambda_{n-1}$,$b=\lambda_n$},
]
% The filled area under the approximate integral
\addplot [integral fill=blue!10] {f} \closedcycle;

% The approximate integral
\addplot [integral line=black] {f};

% The vertical lines between the segments
\addplot [integral, ycomb=blue] {f};

% The function
\addplot [thick, black] {f} node [anchor=south] {$E(\lambda)$};

% The highlighted segment
%\addplot [integral fill=cyan!35, domain=6:7, samples=2] {f} \closedcycle;
\end{axis}
\end{tikzpicture}
  \caption[Trapezium rule]{Trapezium rule as used by functions in package \pkg{photobiology} except when the wavelength step is wide.}\label{fig:trapezium:rule}
\end{figure}

\section{Discontinuous functions}

The integration algorithm described above is reliable only for continuous functions with a continuous derivative (slope). Spectra can be usually considered as continuous in relation to the resolution of spectrometers, as long as an instrument suitable for the measured light source has been used. Most commonly used biological spectral weighting functions (BSWFs) have discontinuities at their extremes wavelengths. They are not infinitely asymptotic but instead at a certain wavelength they abruptly end taking a value of zero past the boundary. A few BSWFs, of which the best known is CIE's erythemal action spectrum are defined as a series of linear segments with different slopes. At the knots connecting a pair of segments, the derivative is discontinuous (the slope changes abruptly).

At their wavelength limits, the same problem affects the integration of wavelength ranges such color definitions/bands. This can introduce large errors when wavelength ranges are narrow, as is the case for the definitions of red and far-red used in plant biology, which are only 10~nm wide.

The way around this problem is to obtain estimates of spectral irradiance very near each side of the discontinuity \emph{before} convolution of the spectral irradiance with the BSWF and/or numerical integration. This is still an approximation that requires additional computer processing, and is not always needed. In the functions in our packages, the user can override the default. The default is conservative, favouring accurate estimates rather than fast performance.

\section{Scaling}\label{sec:algo:scaling}

Scaling consists in multiplying all individual values of the spectral variable by the same numeric constant. For example, if we have spectral irradiance, we could express scaling as:
\begin{equation} \label{eq:scaling}
   E(\lambda) * k = E\prime(\lambda)
\end{equation}

In many cases scaling is used when comparing spectra. For example, we may want to compare two spectra scaled so that they both share the same value for a summary quantity such as total irradiance. A simple case is re-scaling so that the area under two curves for the wavelength interval $400 \mathrm{nm} < \lambda < 700 \mathrm{nm}$ is the same, for example equal to one. We can then scale each spectrum as:

\begin{equation} \label{eq:scaling:par}
   \frac{E(\lambda)}{ \int_{400}^{700} E(\lambda) \mathrm{d}\lambda} = E_s(\lambda)
\end{equation}

In Fig.\ \ref{fig:leds:scaled} we demonstrate scaling according to equation \ref{eq:scaling:par} of the emission spectra of two LEDs, one with a narrow peak of emission, and one with a wide one. Other summary quantities can be used in addition to the integral.

\begin{figure}
  \centering
<<echo=FALSE>>=
my_leds.mspct <- leds.mspct[c("Nichia_unknown_757", "LedEngin_LZ1_10DB00_460nm")]
my_leds_par.mspct <- fscale(my_leds.mspct, f = e_irrad, w.band = PAR())
my_leds_par.spct <- rbindspct(my_leds_par.mspct, idfactor = "LED")
ggplot(my_leds_par.spct) + aes(linetype = LED) + stat_wb_mean(w.band = PAR(), alpha = 0.1) + geom_line() + theme_bw() + theme(legend.position="top") + scale_fill_identity() + scale_color_identity()
@
  \caption[Scaling to equal PAR irradiance]{Scaling to equal PAR irradiance of the emission spectra of a blue and a white LED. The areas of the two exactly coincident faint rectangles represent the PAR irradiance integral under each of the two curves.}\label{fig:leds:scaled}
\end{figure}

\section{Normalization}\label{sec:algo:normalization}

Normalization consists in scaling a spectrum so that the spectral quantity is equal to one at a certain wavelength. The most common normalization is to scale so that the maximum value of a spectral quantity is equal to one, in other words, we scale the spectrum by dividing it by the value at the highest peak. This case, more formally stated in equation \ref{eq:norm:max}, is exemplified in Fig.\ \ref{fig:leds:normalized}.

\begin{equation} \label{eq:norm:max}
   \frac{E(\lambda)}{\max E(\lambda)} = E_{n}(\lambda)
\end{equation}

In some cases, normalization is done at a specific wavelength. A well known example is the normalization at $\lambda = 300 \mathrm{nm}$ of BSWFs used in the quantification of ultraviolet radiation in biological studies.

\begin{equation} \label{eq:norm:wl}
   \frac{\mathcal{E}(\lambda)}{\mathcal{E}(\lambda = 300)} = \mathcal{E}_{n}(\lambda)
\end{equation}

Where $\mathcal{E}(\lambda)$ is the spectral effectiveness.

\begin{figure}
  \centering
<<echo=FALSE>>=
my_leds_450.mspct <- leds.mspct[c("Nichia_unknown_757",
                                  "LedEngin_LZ1_10DB00_460nm")]
my_leds_450.spct <- rbindspct(my_leds_450.mspct, idfactor = "LED")
ggplot(my_leds_450.spct) +
  aes(linetype = LED) +
  stat_wb_column(w.band = PAR(), alpha = 0.2, color = "grey") +
  geom_line() +
  theme_bw() +
  theme(legend.position = "top") +
  scale_fill_identity()
@
  \caption[Normalization at peak]{Normalization of the emission spectra of a blue and a white LED to one at peak of maximum emission. The areas of the faint rectangles represent the PAR irradiance integral under each of the two curves.}\label{fig:leds:normalized}
\end{figure}

\section{Interpolation}

\section{Astronomy}

Starting from version 0.9.12 of package \pkg{photobiology} astronomical calculations are done according to the algorithms in the book \citetitle{Meeus1998} \autocite{Meeus1998}. See \url{http://www.esrl.noaa.gov/gmd/grad/solcalc/calcdetails.html} for additional details and an on-line calculator.

\subsection{Times to events}

\subsection{Position of the sun}

\section{Array-detector spectrometers}

Contrary to detectors in digital photographic cameras which have square pixels arranged in a 2-dimensional grid, most array spectrometers have 1-dimensional arrays with rectangular pixels. Some exceptions exists with detectors with a very asymmetric but still 2-dimensional shape with a few pixels (e.g.\ 4) across the narrower dimension. A monochromator, usually with the aid of mirror optics projects the different wavelength components (colours) of the incoming light signal onto different pixels.

A detector pixel in a charge-coupled-device (CCD) can be thought of as a ``bucket'' or well collecting incoming photons. The integration time, is the time during which photons are collected by the pixels. At the end of this period the charge accumulated in each pixel is read. After the reading is taken, the ``buckets'' are emptied to get them ready for the next reading. Array detectors in miniature spectrometers can have detector arrays with from 128 to nearly 4000 pixels. Optical filters may be placed on the detector or at the spectrometer entrance.

Depending on the quantity to be measured, different entrance optics, either directly attached or connected through a optical fibre, are used. For irradiance, a cosine diffusor is required. For surface reflectance special probes are available with a relatively narrow angle of acceptance and integrating spheres allowing measurement of scattered plus directly transmitted  radiation and specular plus scattered (total) reflectance. In the case of liquid samples, cuvette holders are used and also in this case, turbid suspensions will scatter light and will require special equipment.

Being array-detector spectrometers by necessity single monochromator instruments they present less than ideal signal:noise ratio (SNR) characteristics and are frequently afflicted by relatively high stray light levels. The electrical dynamic range of array detectors vary from instrument to instrument but depending on the range of wavelengths of interest may be limited by the dynamic range of the signal being measured and the different sensitivity of the detector to different wavelengths as the whole spectrum is acquired at once using the same settings. An additional problem, not exclusive of array spectrometers is the shape of the \emph{slit function} which depends on the width and alignment of the instrument's entrance slit. The ``annomalies'' in slit function may decrease the effective wavelength resolution of spectrometers and introduce a small bias in cases of tail asymmetry.

There are several ways of getting around these problems, some more involved than others. We will give here a broad overview of the different problems and the corrections implemented in package \pkg{ooacquire}.

\subsection{Measurements---problems and solutions}

\subsubsection{Hot and dead pixels}

Most array detectors will have a a few miss-functioning pixels. So called \emph{hot pixels} return a relatively high reading in darkness or are exceptionally sensitive to light. So called \emph{dead pixels} do not respond to radiation. Once identified, the raw counts data from these pixels can be replaced by the average of readings from the two neighbouring pixels. The errors introduced by this operation are usually minor except when measuring lasers or in the case of arrays with few pixels.

\subsubsection{Non-linearity}

The response of each detector pixel is not linear. When the wells are nearly full less charge is \emph{trapped} in the well for each impinging photon. This needs to be corrected by applying a function that compensates for the curvature of the response curve. It is assumed that the same function is valid for all individual pixels in a given detector array. We use the polynomial supplied by Ocean Optics in their calibration certificates, and stored in the instruments' EEPROM. The linearization should be applied to raw counts before substraction of any dark readings, as the actual charge accumulated in the array wells determines the correction needed.

\subsubsection{Dark electrical noise}

To some extent array detectors are sensitive to stimuli other than the photons we are interested in measuring. One important factor is temperature, and the electrical signal returned by a detector kept in total darkness increases with increasing temperature. Any electronic circuit can be also disturbed by electrical fields and interference from the driving computer adding another, smaller source of random noise. This dark signal can be measured and subtracted from measurements. If the random dark noise rapidly varies in time we can reduce this variation by averaging several integrations, both for the dark measurement and the actual measurements. Noise can also be smoothed by averaging nearby pixels using a running mean or running median. Ocean Optics' literature calls this approach boxcar smoothing. Unless the spectrometer has considerably better wavelength resolution than needed for the application at hand, this type of smoothing should be avoided.

\subsubsection{Dynamic range and resolution}

The theoretical dynamic range in a single measurement is rarely achieved. Real values are smaller due to the above mentioned dark signal and its variation, and in some cases stray light. Furthermore, the resolution with respect to number of photons per step in the count depends on the number of bits (binary digits) used to express the result of the count. For example an analogue to digital conversion (ADC) with 16 bits of resolution results in $2^16 = 65536$ discrete numbers or values. Not all spectrometers have electronics have ADCs with 16 bits of resolution. For example the miniature spectrometer model STS from Ocean Optics has an ADC with 14 bits of resolution ($2^14 = 16384$ possible discrete values).

The overall dynamic range of a spectrometer is much larger than for a single measurement, and is mainly given by the range of usable integration times and background optical and electrical noise. One way of reducing the dark noise is to cool either the detector or the whole spectrometer which allows the use of longer integration times and consequently the measurement of weaker light signals, such as fluorescence.

The dynamic range for a single measurement can be increased by \emph{bracketing} the integration time used. In other words we measure under the same illumination conditions using the equivalent of what in photography would be called exposure values. The longer integration time will result in a spectrum with some regions clipped (overexposed). By merging the spectra, using the long integration reading for the ``darker'' regions of the spectrum, and the short one for the brighter parts we may increase the effective dynamic range by an order of magnitude, or even more. However, one should be careful with this approach as the reading from pixels near those saturated (clipped) can be affected by charge leaking from them.

\subsubsection{Stray light}

Stray light is purely an optical phenomenon. Light scattering and reflections within the spectrometer result in radiation of the ``wrong'' wavelength hitting the pixels, resulting in non-zero or too high readings for some pixels. Being an error that is not present unless radiation is entering the spectrometer, it is not compensated by subtraction of a dark reading. If it cannot be controlled through optical means, it needs to be measured and subtracted separately from the dark signal. In the case of our Maya 2000 Pro spectrometers stray light in the UV region originates mainly from visible and specially infrared radiation. In such a case it can be measured by means of a UV-absorbing long pass filter. This measured stray light component can then used to correct the readings.

\subsubsection{Slit function}

Spectral resolution of an array spectrometer depends both on the slit and grating combination used and on how this resolved spectrum is projected onto different pixels. Say a spectrometer with a wide slit may have the wavelength resolution limited by the slit function as even with a monochromatic light source like a laser several pixels can be illuminated. On the other hand an instrument with a narrow slit, and a limited number of relatively large pixels, will have its wavelength resolution limited by the pixels themselves, as light of different wavelengths will be received by different parts of the same individual pixel.

In the case than the pixel resolution is better or similar to the optical resolution, then if the shape of the slit function, usually with rather long tails affecting nearby pixels is characterized for different wavelengths, it can be corrected by deconvolution. This characterization needs to be done only once, unless the alignment of the optical components in changed.

\subsubsection{Wavelength calibration}

The correspondence between pixel positions and wavelengths is calibrated by comparison of certain known emission lines in lamps or sunlight. The wavelength will drift as a function of temperature, but the effect is relatively small unless the temperature change is large. In the case of array spectrometers, as they lack moving parts or a scanning mechanism, the wavelength calibration is quite stable in time as long as the temperature is the same. Ocean Optics provides a wavelength calibration but with the functions in package \pkg{ooacquire} either a calibration stored in the instrument's EEPROM or one supplied by the user can be used.

\subsubsection{Irradiance calibration}

The sensitivity of each pixel to light from a suitable broad spectrum calibration lamp can be used to obtain a coefficient for each pixel to convert the output into irradiance or fluence values. These quantities are absolute quantities and consequently their measurement requires an absolute calibration against a light source and optical bench set up for which the irradiance or fluence are known with enough accuracy.

\subsubsection{Transmittance, reflectance and absorptance}

Transmittance, reflectance and absorptance are relative quantities we are normally measured against know clear or opaque, white, grey or black references. As long as we take into account the integration time, and the apply the linearization correction to the readings, no absolute calibration of the spectrometer is needed. It is important to realize that absorbance ($A$) and optical density (OD) are just different ways of expressing \emph{internal} transmittance.

\subsection{Data processing steps for irradiance}


