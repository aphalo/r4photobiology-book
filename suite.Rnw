<<eval=eval_diag, include=eval_diag, echo=eval_diag, cache=FALSE>>=
opts_knit$get()
search()
getwd()
@

<<echo=FALSE, cache=FALSE>>=
set_parent('r4p.main.Rnw')
opts_knit$set(concordance=TRUE)
@

\chapter{Photobiology R packages}\label{chap:suite}

\begin{abstract}
  In this chapter we describe the suite of R packages for photobiological calculations `\textsf{r4photobiology}', and explain how to install them.
\end{abstract}

%%%%
\section{Expected use and users}

The aim of the suite is to both provide a framework for teaching VIS and UV radiation physics and photobiology through a set of functions and data examples. Furthermore, we expect these functions and data to be useful for active researchers during design of experiments, data analysis and data validation. In particular we hope the large set of example data will make it easy to carry out sanity checks of newly acquired and/or published data.

Given the expected audience of both students and biologists, rather than data analysts, or experienced programmers, we have aimed at designing a consistent and easy to understand paradigm for the analysis of spectral data. The design is based on our own user experience, and on feedback from our students and `early adopters'.

\begin{sidewaysfigure}
\centering
  \begin{tikzpicture}[auto]
    \node [c] (ACQ) {\textbf{A:} acquire};
    \node [b, dashed, below = of ACQ] (acquisition) {\textsl{Data acquisition}};
    \node [a, dashed, below = of acquisition] (raw) {Raw spectral data};
    \path [lr, dashed] (acquisition) -- (raw) node[near start, right]{};

    \node [c, right = of ACQ] (PROCESS) {\textbf{B:} process};
    \node [b, dashed, below = of PROCESS] (calibration) {Instrument-dependent corrections and calibration};
    \path [lr, dashed] (raw) -- (calibration) node[near start, above]{};
    \node [b, below = of calibration] (eda) {EDA (plotting)};
    \path [l] (calibration) -- (eda) node[near start, right]{};
    \node [b, below = of eda] (validation) {Validation\\ (sanity checks)};
    \path [l] (eda) -- (validation) node[near start, right]{};
    \node [a, below = of validation] (spectrum) {spectral data};
    \path [lr] (validation) -- (spectrum) node[near start, right]{};

    \node [c, right = of PROCESS] (SUMMARIZE) {\textbf{C:} summarize};
    \node [b, below = of SUMMARIZE] (combine) {Operations on multiple spectra};
    \path [lr] (spectrum) -- (combine) node[near start, above]{};
    \node [b, below = of combine] (summaries) {Summaries\\ (weighting,\\ integration, colour)};
    \path [l] (combine) -- (summaries) node[near start, above]{};
    \node [b, below = of summaries] (validation2) {Validation\\ (sanity checks)};
    \path [l] (summaries) -- (validation2) node[near start, right]{};
    \node [a, below = of validation2] (summdata) {Summary data};
    \path [lr] (validation2) -- (summdata) node[near start, right]{};

    \node [c, right = of SUMMARIZE] (USE) {\textbf{D:} analyse};
    \node [d, dotted, below = of USE] (stats) {Analysis\\ (time series, model fitting)};
    \path [lr, dotted] (summdata) -- (stats) node[near start, below]{};

\end{tikzpicture}

  \caption[Spectral data \emph{pipeline}]{Data ``pipeline'' from acquisition to analysis of spectral data}\label{fig:data:pipeline}
\end{sidewaysfigure}


\section{The design of the framework}

\begin{figure}
\caption{The elements of the framework used by all packages in the suite.}\label{fig:diagram:paradigm}
  \begin{framed}
  \noindent
    \begin{description}
      \item[\texttt{\textunderscore spct}] Spectral objects are containers for different types of spectral data, data which is referenced to wavelength. These data normally originate in measurements or simulation with models.
      \item[\texttt{\textunderscore multi\textunderscore spct}] Containers for spectral objects are used to store related spectral objects, such as time series of spectral objects or spectral images.
      \item[\texttt{wavebands}] Waveband objects are containers of `instructions' for the quantification of spectral data. In addition to the everyday definition as a range of wavelengths, we include the spectral weighting functions used in the calculation of what are frequently called weighted or effective exposures and doses.
      \item[summary functions] Different summary functions return different quantities through integration over wavelengths and take as arguments spectra and wavebands.
      \item[maths operators and functions] Are used to combine and/or transform spectral data, and in some cases to apply weights defined by wavebands.
    \end{description}
  \end{framed}
\end{figure}

The design of the `high level' interface is based on the idea of achieving simplicity of use by hiding the computational difficulties and exposing objects, functions and operators that map directly to physical concepts. Computations and plotting of spectral data centers on two types of objects: \emph{spectra} and \emph{wavebands} (Figure \ref{fig:diagram:paradigm}). Al spectra have in common that observations are referenced to a wavelength value. However, there are different types spectral objects, e.g.\ for light sources and responses to light. Waveband objects include much more than information about a range of wavelengths, they can also include information about a transformation of the spectral data, like a biological spectral weighting function (BSWF). In addition to functions for calculating summary quantities like irradiance from spectral irradiance, the packages define operators for spectra and wavebands. The use of operators simplifies the syntax and makes the interface easier to use.

A consistent naming scheme as well as consistency in the order of function arguments across the suite.... Data objects are \emph{tidy} as defined by in \autocite{Wickham2013}, in other words data on a row always corresponds to a single observation event, although such an observation can consist in more than one measured or derived quantity. Data from different observations are stored in different objects, or if in the same object they are \emph{keyed} using and index variable.

The same summary methods, are available for \texttt{\textunderscore spct} and \textunderscore multi\textunderscore spct}, in the first case returning a vector, and in the second case, a \texttt{data.frame} object.

Package \texttt{photobiology} can be thought as a framework defining a way of storing spectral data plus `pieces' from which specific summaries can be constructed. Extensibility and reuse is at the core of the design. This is achieved by using the weakest possible assumptions or expectations about data properties and avoiding as much as possible the hard-coding of any constants or size limits. This, of course, has a cost in possibly slower execution speed. Within these constraints an effort has been made to remove performance bottleneck by means of C++ code and passing data objects by reference when possible.

\begin{figure}
 \tikzstyle{every node}=[draw=black,thick,anchor=west,fill=blue!10]
 \tikzstyle{root}=[dashed,fill=gray!50]
  \centering
  \begin{tikzpicture}[%
  grow via three points={one child at (0.5,-0.7) and
  two children at (0.5,-0.7) and (0.5,-1.4)},
  edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]
  \node [root] {data.table}
      child { node {generic\textunderscore spct}
          child { node {cps\textunderscore spct}}
          child { node {source\textunderscore spct}}
          child { node {response\textunderscore spct}}
          child { node {filter\textunderscore spct}}
          child { node {reflector\textunderscore spct}}
          child { node {object\textunderscore spct}}
          child { node {chroma\textunderscore spct}}
    };
  \end{tikzpicture}
  \caption{Classes used to contain different types of spectral data}\label{fig:spct:hierarchy}
\end{figure}

\begin{figure}
 \tikzstyle{every node}=[draw=black,thick,anchor=west,fill=blue!10]
 \tikzstyle{root}=[dashed,fill=gray!50]
  \centering
  \begin{tikzpicture}[%
  grow via three points={one child at (0.5,-0.7) and
  two children at (0.5,-0.7) and (0.5,-1.4)},
  edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]
  \node [root] {list}
      child { node {generic\textunderscore multi\textunderscore spct}
          child { node {cps\textunderscore multi\textunderscore spct}}
          child { node {source\textunderscore multi\textunderscore spct}}
          child { node {response\textunderscore multi\textunderscore spct}}
          child { node {filter\textunderscore multi\textunderscore spct}}
          child { node {reflector\textunderscore multi\textunderscore spct}}
          child { node {object\textunderscore multi\textunderscore spct}}
          child { node {chroma\textunderscore multi\textunderscore spct}}
    };
  \end{tikzpicture}
  \caption{Classes used to contain multiple spectral objects}\label{fig:spct:hierarchy}
\end{figure}

<<suite-design-example, eval=FALSE>>=
e_irrad(sun.spct * polyester.new.spc, CIE())
@

Is all what is needed to obtain the CIE98-weigthed energy irradiance simulating the effect of a polyester filter on the example solar spectrum, which of course, can be substituted by other spectral irradiance and filter data.

When we say that we hide the computational difficulties what we mean, is that in the example above, the data for the two spectra do not need to be available at the same wavelengths values, and the BSWF is defined as a function. Interpolation of the spectral data and calculation of spectral weighting factors takes place automatically and invisibly. All functions and operators function without error with spectra with varying (even arbitrarily and randomly varying) wavelength steps. Integration is always used rather than summation for summarizing the spectral data.

There is a lower layer of functions, used internally, but also exported, which allow improved performance at the expense of more complex scripts and commands. This user interface is not meant for the casual user, but for the user who has to analyse thousands of spectra and uses scripts for this. For such users performance is the main concern rather than easy of use and easy to remember syntax. Also these functions handle any wavelength mismatch by interpolation before applying operations or functions.

The suite also includes data for the users to try options and ideas, and helper functions for plotting spectra using other R packages available from CRAN, in particular \code{ggplot2}. There are some packages, not part of the suite itself, for data acquisition from Ocean Optics spectrometers, and application of special calibration and correction procedures to those data. A future package will provide an interface to the TUV model to allow easy simulation of the solar spectrum.

\section{The suite}

The suite consists in several packages. The main package is \code{photobiology} which contains all the generally useful functions, including many used in the other, more specialized, packages (Table \ref{tab:suite}).

\begin{table}
\newcommand{\gblt}{\textcolor{green}{$\bullet$}}
\newcommand{\yblt}{\textcolor{yellow}{$\bullet$}}
\newcommand{\rblt}{\textcolor{red}{$\bullet$}}
%\newcommand{\gblt}{{$\bullet$}}
%\newcommand{\yblt}{{$\bullet$}}
%\newcommand{\rblt}{{$\bullet$}}
\caption[Packages in the suite]{Packages in the \textsf{r4photobiology} suite. Packages not yet released are
highlighted with a red bullet \rblt, and those at `beta' stage with a yellow bullet \yblt, those relatively stable with a
green bullet \gblt.}\label{tab:suite}
\begin{small}
\begin{tabular}{clll}
\toprule
 & Package           &  Type        & Contents \\
\midrule
\gblt & photobiologyAll   &  dummy          & loads other packages of the suite\\
\gblt & photobiology      &  funs + classes & basic functions, class definitions,\\
      &                   &                 & class methods and example data \\
\yblt & photobiologyInOut     &  functions  & data import/export functions \\
\gblt & photobiologyWavebands   &  definitions & quantification of radiation \\
\gblt & photobiologygg  & functions       & extensions to package \code{ggplot2} \\
\midrule
\midrule
\gblt & photobiologySun   &  data        & spectral data for solar radiation \\
\gblt & photobiologyLamps &  data        & spectral data for lamps \\
\gblt & photobiologyLEDs  &  data        & spectral data for LEDs \\
\gblt & photobiologyFilters  &  data     & transmittance data for filters \\
\gblt & photobiologySensors  &  data     & response data for sensors \\
\yblt & photobiologyReflectors  &  data  & reflectance data for materials \\
\midrule
\yblt & photobiologyPlants  & funs + data & photobiology of plants \\
\midrule
\midrule
\gblt & rOmniDriver      & functions   & Ocean Optics spectrometers \\
\gblt & MayaCalc      & functions   & UV and VIS irradiance data \\
      &               &             & processing for Maya2000 Pro \\
\rblt & rTUV             & funs + data & TUV model interface \\
\bottomrule
\end{tabular}
\end{small}
\end{table}

Spectral irradiance objects (class \code{source\_spct}) and spectral response/action objects (class \code{response\_spct}) can be constructed using energy- or photon-based data, but this does not affect their behaviour. The same flexibility applies to
spectral transmittance vs.\ spectral absorbance for classes \code{filter\_spct}, \code{reflector\_spct} and \code{object\_spct}.

Although by default low-level functions expect spectral data on energy units, this is just a default that can be changed by setting the parameter \code{unit.in = "photon"}. Across all data sets and functions wavelength vectors have name \code{w.length}, spectral (energy) irradiance \code{s.e.irrad}, photon spectral irradiance \code{s.q.irrad}\footnote{\code{q} derives from `quantum'.}, absorbance ($\log_{10}$-based) \code{A}, transmittance (fraction of one) \code{Tfr}, transmittance (\%) \code{Tpc}, reflectance (fraction of one) \code{Rfr}, reflectance (\%) \code{Rpc}, and absorptance (fraction of one) \code{Afr}.

Wavelengths should always be in nm, and when conversion between energy and photon based units takes place no scaling factor is used (an input in \wattnm yields an output in \molnm rather than \umolnm).

The suite is still under active development. Even those packages marked as `stable' are likely to acquire new functionality. By stability, we mean that we hope to be able to make most changes backwards compatible, in other words, we hope they will not break existing user code.

%%%%
\section{The \lowercase{\textsf{r4photobiology}} repository}\label{sec:photoCRAN}
% \lowercase needed for page headers

I have created a repository for the packages. This repository follows the CRAN folder structure, so package installation can be done using normal R commands. This means that dependencies are installed automatically and that automatic updates are possible. The build most suitable for the current system and R version is also picked automatically if available. It is normally recommended that you do installs and updates on a clean R session (just after starting R or RStudio). For easy installation and updates of packages, the r4photobiology repository can be added to the list of repositories that R knows about.

Whether you use RStudio or not it is possible to add the r4photobiology repository to the current session as follows, which will give you a menu of additional repositories to activate:

<<eval=FALSE, tidy=FALSE>>=
setRepositories(
  graphics = getOption("menu.graphics"),
  ind = NULL,
  addURLs = c(r4photobiology = "http://www.r4photobiology.info/R"))
@

If you know the indexes in the menu you can use this code, where ‘1’ and ‘6’ are the entries in the menu in the command above.

<<eval=FALSE, tidy=FALSE>>=
setRepositories(
  graphics = getOption("menu.graphics"),
  ind = c(1, 6),
  addURLs = c(r4photobiology = "http://www.r4photobiology.info/R"))
@

Be careful not to issue this command more than once per R session, otherwise the list of repositories gets corrupted by having two repositories with the same name.

Easiest is to create a text file and name it `\code{.Rprofile}', unless it already exists. The commands above (and any others you would like to run at R start up) should be included, but with the addition that the package names for the functions need to be prepended. So previous example becomes:

<<eval=FALSE, tidy=FALSE>>=
utils::setRepositories(
  graphics = getOption("menu.graphics"),
  ind = c(1, 6),
  addURLs = c(r4photobiology = "http://www.r4photobiology.info/R"))
@

The \code{.Rprofile} file located in the current folder is sourced at R start up. It is also possible to have such a file affecting all of the user's R sessions, but its location is operating system dependent, it is in most cases what the OS considers the current user's \textit{HOME} directory or folder (e.g. `My Documents' in recent versions of MS-Windows). If you are using RStudio, after setting up this file, installation and updating of the packages in the suite can take place exactly as for any other package archived at CRAN.

The commands and examples below can be used at the R prompt and in scripts whether RStudio is used or not.

After adding the repository to the session, it will appear in the menu when executing this command:
<<eval=FALSE>>=
setRepositories()
@
and can be enabled and disabled.

In RStudio, after adding the \textsf{r4photobiology} repository as shown above, the photobiology packages can be installed and uninstalled through the normal RStudio menus and dialogues, and will listed after typing the first few characters of their names. For example when you type ‘photob’ in the packages field, all the packages with names starting with ‘photob’ will be listed.

They can be also installed at the R command prompt with the following command:
<<eval=FALSE>>=
install.packages(c("photobiologyAll", "photobiologygg"))
@


and updated with:
<<eval=FALSE>>=
update.packages()
@


The added repository will persist only during the current R session. Adding it permanently requires editing the R configuration file, as discussed above. Take into consideration that \texttt{.Rprofile} is read by R itself, and will take effect whether you use RStudio or not. It is possible to have an user-account wide .Rprofile file, and a different one on those folders needing different settings. Many other R options can also be modified by means of commands in the .Rprofile file.

